# Dense_Captioning-
A project inspired by ImageNet.
Object detection using VGG16, ResNet50, Inception V3 CNN models on Flickr 8k dataset through Keras.
Compared the accuracy of above three CNN models - VGG16 - 40%, ResNet - 90%, Inception V3 - 38%.
Leveraged LSTM RNN model to generate image captions.

Note: The Object_detection ppt contains all the outputs of the code. 

Predicted outputs:

![xyz](https://github.com/ekantbagri/Dense_Captioning-/blob/main/Capture.PNG?raw=true)


loss curve graph for VGG16:


![xyz](https://github.com/ekantbagri/Dense_Captioning-/blob/main/Capture1.PNG?raw=true)


